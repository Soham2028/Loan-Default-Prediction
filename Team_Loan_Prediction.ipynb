{"cells":[{"cell_type":"code","source":["# Load the packages needed for this part\n# create spark and sparkcontext objects\nfrom pyspark.sql import SparkSession\nimport numpy as np\n\nspark = SparkSession.builder.getOrCreate()\nsc = spark.sparkContext\n\nimport pyspark\nfrom pyspark.ml import feature, regression, Pipeline, classification, pipeline, evaluation\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.sql import functions as fn, Row\nfrom pyspark.sql.functions import when, regexp_extract, col\nfrom pyspark import sql\nfrom pyspark.sql.functions import *\n\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.feature import VectorIndexer\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport sys"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#Genrating system version\nsys.version"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["#Reading the csv file into spark \npd.set_option('display.max_columns', 500)\nloan_df = spark.read.csv('/FileStore/tables/loan_default.csv', header=True, inferSchema=True)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["#Creating a copy of the original dataframe\nloan_copy_df = loan_df\nloan_copy_df = loan_copy_df\nloan_copy_df.toPandas().head()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["#Exploratory Data Analysis"],"metadata":{}},{"cell_type":"code","source":["#Checking for null values\nloan_copy_df.select([count(when(isnan(c), c)).alias(c) for c in loan_copy_df.columns]).toPandas().head()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["#Getting the count of each categorical variables\nloan_copy_df.groupBy('year').count().show()\nloan_copy_df.groupBy('home_ownership', 'home_ownership_cat').count().sort('home_ownership_cat').show()\nloan_copy_df.groupBy('income_category', 'income_cat').count().sort('income_cat').show()\nloan_copy_df.groupBy('interest_payments', 'interest_payment_cat').count().sort('interest_payment_cat').show()\nloan_copy_df.groupBy('term', 'term_cat').count().sort('term_cat').show()\nloan_copy_df.groupBy('application_type', 'application_type_cat').count().sort('application_type_cat').show()\nloan_copy_df.groupBy('purpose', 'purpose_cat').count().sort('purpose_cat').show()\nloan_copy_df.groupBy('grade', 'grade_cat').count().sort('grade_cat').show()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["#List of Column names present in the dataframe and their types\nloan_copy_df.dtypes"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["#Descriptive Statistics applied on our Loan Dataset\nloan_copy_df.toPandas().describe()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["loan_copy_df.toPandas().head()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["#Renaming Target variable i.e. Loan_Condition_Cat to Default\nloan_copy_df = loan_copy_df.withColumnRenamed('loan_condition_cat', 'default')"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["#Correlation Matrix of the numerical orders of all the categorical variables \nplt.figure(figsize=(18, 12))\ncorr = loan_copy_df.toPandas().corr()\nax = sns.heatmap(corr, cmap=\"YlGnBu\", annot=True)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right'\n);\ndisplay(ax.figure)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["#Plotting loan applications per year\nplt.figure(figsize=(12,6))\nax_yearCat = sns.countplot(x='year',data=loan_copy_df.toPandas())\nax_yearCat.set_title('Loan applicants per Year')\nax_yearCat.set_ylabel('Count')\nax_yearCat.set_xlabel('Year')\ndisplay(ax_yearCat.figure)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["#Visualizing the categorical variables\n#Counting number of defaulters in income categories\nplt.figure(figsize=(12,6))\nax_incomeCat = sns.countplot(x='income_category',data=loan_copy_df.toPandas(), hue='default')\n\nax_incomeCat.set_title('Loan defaults based on income')\nax_incomeCat.set_ylabel('Count')\nax_incomeCat.set_xlabel('Income Category')\ndisplay(ax_incomeCat.figure)\n#A comparatively larger number of low income people have defaulted their loans"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["#counting the number of defaulters across different purpose categories\nplt.figure(figsize=(20,7))\nax_purposeCat = sns.countplot(x='purpose', data=loan_copy_df.toPandas(), hue='default')\nax_purposeCat.set_xticklabels(ax_purposeCat.get_xticklabels(), rotation=20)\nax_purposeCat.set_title('Purpose for applying Loan')\nax_purposeCat.set_ylabel('Count')\nax_purposeCat.set_xlabel('Purpose')\n\ndisplay(ax_purposeCat.figure)\n\n#A comparatively larger number of purpose category 6 which is debt consolidation people have defaulted their loans"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["#counting the number of defaulters across different term categories\nplt.figure(figsize=(7,4))\nax_termCat = sns.countplot(x='term', data=loan_copy_df.toPandas(), hue='default')\nax_termCat.set_title('Loan Duration')\nax_termCat.set_ylabel('Count')\nax_termCat.set_xlabel('Terms')\ndisplay(ax_termCat.figure)\n\n#A comparatively larger number of 36 month term people have defaulted their loans"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["#Relationship between fairly correlated features from the correlation chart\n#loan amount and installments they are 94% correlated\nloan_inst = loan_copy_df.toPandas().plot.scatter(x = 'loan_amount', y = 'installment', color = 'DarkBlue')\nloan_inst.title.set_text('Loan Amount Vs Installment')\n\ndisplay(loan_inst.figure)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["#Plotting scatter graph of Installment vs Grade \nloan_purpose = loan_copy_df.toPandas().plot.scatter(x = 'grade_cat', y = 'interest_rate', color = 'Green')\nloan_purpose.title.set_text('Installment Rate Vs Grade')\ndisplay(loan_purpose.figure)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["#The regression line plot of Grade category and interest rate\nloan_grade = sns.regplot(x='grade_cat', y='interest_rate', data=loan_copy_df.toPandas())\ndisplay(loan_grade.figure)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["#detecting outliers with annual income and defaulters\nplt.figure(figsize=(5,5))\nsns.set_style(\"whitegrid\")\nannual_inc_box = sns.boxplot(x='default', y='annual_inc', data=loan_copy_df.toPandas())\nannual_inc_box.set_title('Default based on Annual Income ')\n\nannual_inc_box.set(ylim=(0, 500000))\ndisplay(annual_inc_box.figure)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["#detecting outliers with defaulters and installment\nplt.figure(figsize=(5,5))\nsns.set_style(\"whitegrid\")\nloan_box = sns.boxplot(x='default', y='installment', data=loan_copy_df.toPandas())\nloan_box.set_title('Default based on Monthly Installment ')\n#loan_box.set(ylim=(0, 100000))\ndisplay(loan_box.figure)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["#detecting outliers with purpose and installment\nplt.figure(figsize=(6,5))\nsns.set_style(\"whitegrid\")\npurpose_box = sns.boxplot(x='purpose', y='installment', data=loan_copy_df.toPandas())\npurpose_box.set_xticklabels(ax_purposeCat.get_xticklabels(), rotation=35)\npurpose_box.set_title('Purpose for applying Loan')\npurpose_box.set_ylabel('Installments')\npurpose_box.set_xlabel('Purpose')\n\ndisplay(purpose_box.figure)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["#Filtering out bad loans to analyze\nbad_loans = loan_copy_df.toPandas().loc[loan_copy_df.toPandas().default == 1]"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["#Filtering out good loans to analyze\ngood_loans = loan_copy_df.toPandas().loc[loan_copy_df.toPandas().default == 0]"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["bad_loans.head()"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["#detecting outliers with home purpose and annual_income in bad_loans\nplt.figure(figsize=(7,7))\nsns.set_style(\"whitegrid\")\nhome_ann_box = sns.boxplot(x='purpose', y='loan_amount', data=bad_loans)\nhome_ann_box.set(ylim=(0, 50000))\ndisplay(home_ann_box.figure)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["#detecting outliers with home purpose and annual_income in good_loans\nplt.figure(figsize=(10,7))\nsns.set_style(\"whitegrid\")\nhome_good_box = sns.boxplot(x='purpose', y='annual_inc', data=good_loans)\nhome_good_box.set(ylim=(0, 500000))\ndisplay(home_good_box.figure)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["#Creating a pandas dataframe with only the bad loans\ndata = bad_loans['home_ownership'].value_counts()\nBad_loans_home_sum = pd.DataFrame(data)\nBad_loans_home_sum.reset_index(level = 0, inplace=True)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["# Creating a pie diagram of categories with the bad loans\n# Create a list of colors (from iWantHue)\ncolors = [\"#E13F29\", \"#D69A80\", \"#D63B59\", \"#AE5552\", \"#CB5C3B\", \"#EB8076\", \"#96624E\", \"#96624F\", \"#96524E\"]\n\n# Create a pie chart\nfig = plt.figure(figsize=(4,4))\nplt.pie(\n    # using data total)arrests\n    Bad_loans_home_sum['home_ownership'],\n    # with the labels being officer names\n    labels=Bad_loans_home_sum['index'],\n    # with no shadows\n    shadow=True,\n    # with colors\n    colors=colors,\n    # with one slide exploded out\n    explode=(0, 0, 0.15, 0, 0),\n    # with the start angle at 90%\n    startangle=90,\n    # with the percent listed as a fraction\n    autopct='%1.1f%%',\n    )\n\n# View the plot drop above\nplt.axis('equal')\n\n# View the plot\nplt.tight_layout()\nplt.title('Types of bad loan home owners')\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["#Creating a pandas dataframe with only the good loans\ndata = good_loans['home_ownership'].value_counts()\ngood_loans_home_sum = pd.DataFrame(data)\ngood_loans_home_sum.reset_index(level = 0, inplace=True)\ngood_loans_home_sum"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["# Creating a pie chart of categories with only the good loans\n# Create a list of colors (from iWantHue)\ncolors = [\"#E13F29\", \"#D69A80\", \"#D63B59\", \"#AE5552\", \"#CB5C3B\", \"#EB8076\", \"#96624E\", \"#96624F\", \"#96524E\"]\n\n# Create a pie chart\nfig_good = plt.figure(figsize=(4,4))\nplt.pie(\n    # using data total)arrests\n    good_loans_home_sum['home_ownership'],\n    # with the labels being officer names\n    labels=good_loans_home_sum['index'],\n    # with no shadows\n    shadow=True,\n    # with colors\n    colors=colors,\n    # with one slide exploded out\n    explode=(0, 0, 0.15, 0, 0, 0),\n    # with the start angle at 90%\n    startangle=90,\n    # with the percent listed as a fraction\n    autopct='%1.1f%%',\n    )\n\n# View the plot drop above\nplt.axis('equal')\n\n# View the plot\nplt.tight_layout()\nplt.title('Types of good loan home owners')\ndisplay(fig_good)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["#Plotting counts of different categories in Grade\nplt.figure(figsize = (6,6))\nsns.countplot(x=\"grade\",data=loan_copy_df.toPandas(), palette= \"YlGnBu\")\nplt.xticks(rotation=10)\nplt.title(\"Grade\", fontsize=20)\nplt.xlabel(\"Grade\", fontsize=10)\nplt.ylabel(\"Number of Loans\", fontsize=20)\ndisplay(plt.draw())"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["#Counting the different loan conditions according to their issue dates\nfig, ax = plt.subplots(figsize=(7,5))\nloan_copy_df.toPandas().groupby(['issue_d']).count()['loan_condition'].plot(ax=ax)\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["#Creating a pie chart of percentages of good loan and bad loans\nf, ax = plt.subplots(figsize=(12,8))\n\ncolors = [\"#3791D7\", \"#D72626\"]\nlabels =\"Good Loan\", \"Bad Loan\"\n\nplt.suptitle('Loan Condition', fontsize=20)\nplt.axis('off')\n\nloan_copy_df.toPandas().loan_condition.value_counts().plot.pie(explode=[0,0.25], autopct='%1.2f%%', shadow=True, colors=colors, \n                                             labels=labels, fontsize=12, startangle=70)\ndisplay(f)"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["#Detecting outliers through violin and box plots\nfig, ((ax1), (ax2))= plt.subplots(nrows=1, ncols=2, figsize=(14,6))\n\nsns.violinplot(x=\"grade\", y=\"loan_amount\", data=loan_copy_df.toPandas(), palette=\"Set2\", ax=ax1)\nsns.boxplot(x=\"grade\", y=\"total_pymnt\", data=loan_copy_df.toPandas(), palette=\"Set2\", ax=ax2)\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["#Feature Engineering"],"metadata":{}},{"cell_type":"code","source":["#Creating dummy variables for all the categorical ordinal variables\ndummy = loan_copy_df.toPandas()\ndummy_loanCondition = pd.get_dummies(dummy['loan_condition'])\ndummy_loanCondition = pd.concat([dummy, dummy_loanCondition], axis = 1)\n\ndummy_gradeCat = dummy_loanCondition\ndummy_gradeCat = pd.get_dummies(dummy_gradeCat['grade'])\ndummy_gradeCat = pd.concat([dummy_loanCondition, dummy_gradeCat], axis = 1)\n\ndummy_homeOwnCat = dummy_gradeCat\ndummy_homeOwnCat = pd.get_dummies(dummy_homeOwnCat['home_ownership'])\ndummy_homeOwnCat = pd.concat([dummy_gradeCat, dummy_homeOwnCat], axis = 1)\n\ndummy_incomeCat = dummy_homeOwnCat\ndummy_incomeCat = pd.get_dummies(dummy_incomeCat['income_category'])\ndummy_incomeCat = pd.concat([dummy_homeOwnCat, dummy_incomeCat], axis = 1)\n\ndummy_purposeCat = dummy_incomeCat\ndummy_purposeCat = pd.get_dummies(dummy_purposeCat['purpose'])\ndummy_purposeCat = pd.concat([dummy_incomeCat, dummy_purposeCat], axis = 1)\n\ndummy_termCat = dummy_purposeCat\ndummy_termCat = pd.get_dummies(dummy_termCat['term_cat'])\ndummy_termCat = pd.concat([dummy_purposeCat, dummy_termCat], axis = 1)\n\nloan_dummy_df = dummy_termCat\n\n#loan_dummy_df = loan_dummy_df.drop(['Good Loan', 'Bad Loan', 'ANY', '3', 'other', '60 months'], axis=1)"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["#dropping the reference variables of the categorical dummies\nloan_dummy_df_final = loan_dummy_df.drop(['G', 'Low', 'Good Loan', 'Bad Loan', 'ANY', 'other'], axis = 1)\nloan_dummy_df_final1 = loan_dummy_df_final.drop(2, axis = 1)"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["#Rounding the interest rate\nloan_dummy_df_final1['interest_rate'] = loan_dummy_df_final1['interest_rate'].round(0)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["#Creating a spark dataframe with the dataset containing dummies and preapring for linear regression\nloan_linear_reg = spark.createDataFrame(loan_dummy_df_final1)"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["loan_dummy_df_final1.head()"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["#Creating a columns list for multiple logistic regressin and casting them as integer data type\ncolumns_list = ['loan_amount','default','dti','total_pymnt','total_rec_prncp','recoveries','installment','interest_rate','A','B','C','D','E','F','MORTGAGE','NONE','OTHER','OWN','RENT','High','Medium','car','credit_card','debt_consolidation','educational','home_improvement','house','major_purchase','medical','moving','renewable_energy','small_business','vacation','wedding','1']\n\nfor col in columns_list:\n  loan_linear_reg = loan_linear_reg.withColumn(col, loan_linear_reg[col].cast('Integer'))"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":["#Model Creation"],"metadata":{}},{"cell_type":"code","source":["#Splitting the dataset \ntraining_df, validation_df, testing_df = loan_linear_reg.randomSplit([0.6, 0.3, 0.1], seed=100)"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["#Importing pyspark libraries for machine learning\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import VectorAssembler, StandardScaler\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"markdown","source":["##Building a classification model using Logistic Regression"],"metadata":{}},{"cell_type":"code","source":["#Intial steps of performing balancing ratio for remedies of class imbalance\n#Retreiving the ratio of good loans and bad loans separately out of the total datasize\ndataset_size=float(training_df.select(\"default\").count())\nnumPositives=training_df.select(\"default\").where('default == 0').count()\nper_ones=(float(numPositives)/float(dataset_size))*100\nnumNegatives=float(dataset_size-numPositives)\nprint('The number of ones are {}'.format(numPositives))\nprint('Percentage of ones are {}'.format(per_ones))"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["#Balancing Ratio continued: \nBalancingRatio= numNegatives/dataset_size\nprint('BalancingRatio = {}'.format(BalancingRatio))"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":["#Assigning class weights\ntraining_df=training_df.withColumn(\"classWeights\", fn.when(training_df.default == 0,BalancingRatio).otherwise(1-BalancingRatio))\ntraining_df.select(\"classWeights\").show(5)"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["#Including a set of column for logistic regression\ncols = ['total_pymnt','loan_amount', 'dti', 'installment', 'total_rec_prncp', 'interest_rate', 'A', 'B', 'C', 'D', 'E', 'F', 'MORTGAGE','NONE','OTHER','OWN','RENT', 'car','credit_card','debt_consolidation','educational','home_improvement','house','major_purchase','medical','moving','renewable_energy','small_business','vacation','wedding','1']\n\n#Creating VectorAssembler, StandardScalar and logistic regression model\nva = VectorAssembler(inputCols=cols, outputCol='features')\nsc = StandardScaler(withMean=True, withStd=False, inputCol='features', outputCol='std_features')\nlr = LogisticRegression().setLabelCol('default').setFeaturesCol('std_features').setWeightCol('classWeights')\n\n#Creaging a pipeline of the tasks above and fitting the model\nlr_Model = Pipeline(stages=[va,sc, lr]).fit(training_df)\nlr_prediction = lr_Model.transform(testing_df)"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["#Understanding the prediction outcome\nlr_prediction.select(\"prediction\", \"default\", \"features\").show()"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":["#Accuracy of Logistic Regression\nevaluator = BinaryClassificationEvaluator(labelCol = 'default')\nlr_accuracy = evaluator.evaluate(lr_Model.transform(validation_df))\nprint(\"Accuracy of LogisticRegression is = %g\"% (lr_accuracy))\nprint(\"Test Error of LogisticRegression = %g \" % (1.0 - lr_accuracy))"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"code","source":["#Accuracy of Logistic Regression on the testing Dataframe\nAUC_test = evaluator.evaluate(lr_Model.transform(testing_df))\nprint(AUC_test)"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"code","source":["#Plotting the ROC curve of accuracy\ntrainingSummary = lr_Model.stages[-1].summary\nroc = trainingSummary.roc.toPandas()\nplt.plot(roc['FPR'],roc['TPR'])\nplt.ylabel('False Positive Rate')\nplt.xlabel('True Positive Rate')\nplt.title('ROC Curve')\na = plt.show()\ndisplay(a)"],"metadata":{},"outputs":[],"execution_count":54},{"cell_type":"code","source":["print('Training set areaUnderROC: ' + str(trainingSummary.areaUnderROC))"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"code","source":["#Plotting the Recall vs Precision graph (Visualizing confusion matrix)\npr = trainingSummary.pr.toPandas()\nplt.plot(pr['recall'],pr['precision'])\nplt.ylabel('Precision')\nplt.xlabel('Recall')\nb = plt.show()\ndisplay(b)"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"code","source":["#Creating the confusion matrix\ntp = lr_prediction[(lr_prediction.default == 0) & (lr_prediction.prediction == 0)].count()\ntn = lr_prediction[(lr_prediction.default == 1) & (lr_prediction.prediction == 1)].count()\nfp = lr_prediction[(lr_prediction.default == 1) & (lr_prediction.prediction == 0)].count()\nfn = lr_prediction[(lr_prediction.default == 0) & (lr_prediction.prediction == 1)].count()\nprint(\"True Positives:\", tp)\nprint(\"True Negatives:\", tn)\nprint(\"False Positives:\", fp)\nprint(\"False Negatives:\", fn)"],"metadata":{},"outputs":[],"execution_count":57},{"cell_type":"code","source":["#Plotting the confusion matrix\narray = [[tp,fn],\n     [fp,tn]]        \ndf_cm = pd.DataFrame(array, range(2),\n                  range(2))\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.2)#for label size\nsns.heatmap(df_cm, annot=True, annot_kws={\"size\": 10}, cmap='YlGnBu', fmt='g')\nplt.title('Confusion Matrix for Logistic Regression \\n ')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.gca().invert_xaxis()\nplt.gca().invert_yaxis()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":58},{"cell_type":"code","source":["#Extracting the feature importances of the logistic regression model and sorting the variables from highest to lowest order of importance\nlr_feature = pd.DataFrame(list(zip(training_df.toPandas()[cols], lr_Model.stages[-1].coefficients.toArray())),\n            columns = ['column', 'weight']).sort_values('weight')"],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"markdown","source":["##Hyper Parameter Tuning"],"metadata":{}},{"cell_type":"code","source":["# Create ParamGrid for Cross Validation (Grid search and evaluator)\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nparamGrid_lr = (ParamGridBuilder()\n                .addGrid(lr.regParam, [0.05, 0.01, 0.2])\n             .addGrid(lr.elasticNetParam, [0.3, 0.1])\n             .build())"],"metadata":{},"outputs":[],"execution_count":61},{"cell_type":"code","source":["from time import *\nstart_time = time()\n\n# Create 3-fold CrossValidator\ncv_lr = CrossValidator(estimator=lr,\n                    estimatorParamMaps=paramGrid_lr,\n                    evaluator=evaluator, numFolds=3)\n\n# Run cross validations\ncvModel = Pipeline(stages=[va, sc, cv_lr]).fit(training_df)\n# likely take a fair amount of time\nend_time = time()\nelapsed_time = end_time - start_time\nprint(\"Time to train model: %.3f seconds\" % elapsed_time)"],"metadata":{},"outputs":[],"execution_count":62},{"cell_type":"code","source":["#Extracting the best model \nbestModel = cvModel.stages[-1].bestModel\nbestModel.extractParamMap()"],"metadata":{},"outputs":[],"execution_count":63},{"cell_type":"code","source":["#Fitting the best model on the training data\nreg_lr_Model = Pipeline(stages=[va, sc, bestModel]).fit(training_df)\nreg_lr_prediction = reg_lr_Model.transform(testing_df)\nreg_lr_prediction.select(\"prediction\", \"default\", \"features\").show()"],"metadata":{},"outputs":[],"execution_count":64},{"cell_type":"code","source":["#Accuracy of Logistic Regression\nevaluator = BinaryClassificationEvaluator(labelCol = 'default')\nreg_lr_accuracy = evaluator.evaluate(reg_lr_Model.transform(validation_df))\nprint(\"Accuracy of LogisticRegression is = %g\"% (reg_lr_accuracy))\nprint(\"Test Error of LogisticRegression = %g \" % (1.0 - reg_lr_accuracy))"],"metadata":{},"outputs":[],"execution_count":65},{"cell_type":"code","source":["#Plotting the ROC curve of the best model\ntrainingSummary = reg_lr_Model.stages[-1].summary\nroc = trainingSummary.roc.toPandas()\nplt.plot(roc['FPR'],roc['TPR'])\nplt.ylabel('False Positive Rate')\nplt.xlabel('True Positive Rate')\nplt.title('ROC Curve')\na = plt.show()\ndisplay(a)"],"metadata":{},"outputs":[],"execution_count":66},{"cell_type":"code","source":["#Plotting the recall and precision graph \npr = trainingSummary.pr.toPandas()\nplt.plot(pr['recall'],pr['precision'])\nplt.ylabel('Precision')\nplt.xlabel('Recall')\nb = plt.show()\ndisplay(b)"],"metadata":{},"outputs":[],"execution_count":67},{"cell_type":"code","source":["#Extracting the feature importances by the best model\nlr_best_feature = pd.DataFrame(list(zip(training_df.toPandas()[cols], reg_lr_Model.stages[-1].coefficients.toArray())),\n            columns = ['column', 'weight']).sort_values('weight', ascending=False)"],"metadata":{},"outputs":[],"execution_count":68},{"cell_type":"code","source":["lr_best_feature"],"metadata":{},"outputs":[],"execution_count":69},{"cell_type":"code","source":["#Creating the confusion matrix for visualization\ntp = reg_lr_prediction[(reg_lr_prediction.default == 0) & (reg_lr_prediction.prediction == 0)].count()\ntn = reg_lr_prediction[(reg_lr_prediction.default == 1) & (reg_lr_prediction.prediction == 1)].count()\nfp = reg_lr_prediction[(reg_lr_prediction.default == 1) & (reg_lr_prediction.prediction == 0)].count()\nfn = reg_lr_prediction[(reg_lr_prediction.default == 0) & (reg_lr_prediction.prediction == 1)].count()\nprint(\"True Positives:\", tp)\nprint(\"True Negatives:\", tn)\nprint(\"False Positives:\", fp)\nprint(\"False Negatives:\", fn)"],"metadata":{},"outputs":[],"execution_count":70},{"cell_type":"code","source":["#Visualizing the confusion matrix\narray = [[tp,fn],\n     [fp,tn]]        \ndf_cm = pd.DataFrame(array, range(2),\n                  range(2))\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.2)#for label size\nsns.heatmap(df_cm, annot=True, annot_kws={\"size\": 10}, cmap='YlGnBu', fmt='g')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.gca().invert_xaxis()\nplt.gca().invert_yaxis()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":71},{"cell_type":"markdown","source":["##Building a classification model using Decision Tree"],"metadata":{}},{"cell_type":"markdown","source":["### Under Sampling the dataset due to highy imbalanced classes"],"metadata":{}},{"cell_type":"code","source":["#Undersampling the dataset with good loans to take care of the Imbalanced dataset\ngood_loans = loan_linear_reg.filter(loan_linear_reg.default == 0)\nbad_loans = loan_linear_reg.filter(loan_linear_reg.default == 1)\nsampleRatio = bad_loans.count() / loan_linear_reg.count()\ngood_loansSampleDf = good_loans.sample(False, sampleRatio)\nloan_linear_reg1 = bad_loans.unionAll(good_loansSampleDf)"],"metadata":{},"outputs":[],"execution_count":74},{"cell_type":"code","source":["loan_linear_reg1.groupby('default').count().show()"],"metadata":{},"outputs":[],"execution_count":75},{"cell_type":"code","source":["#Splitting the dataset \ntraining_df1, validation_df1, testing_df1 = loan_linear_reg1.randomSplit([0.6, 0.3, 0.1], seed=100)"],"metadata":{},"outputs":[],"execution_count":76},{"cell_type":"code","source":["#Creating tasks for decision tree, VectorAssembler, Standard Scalar and Decision Tree\nvaD = VectorAssembler(inputCols=['total_pymnt','loan_amount','installment','total_rec_prncp','interest_rate','A', 'B', 'C','D','E','F', 'MORTGAGE','NONE','OTHER','OWN','RENT','car','dti','credit_card','debt_consolidation','educational','home_improvement','house','major_purchase','medical','moving','renewable_energy','small_business','vacation','wedding','1'], outputCol='features')\nsc = StandardScaler(withMean=True, withStd=False, inputCol='features', outputCol='std_features')\ndt = DecisionTreeClassifier(featuresCol='std_features', labelCol='default')\n\n#Creating a pipeline for the above tasks\ndt_model = Pipeline(stages=[vaD, sc, dt]).fit(training_df1)"],"metadata":{},"outputs":[],"execution_count":77},{"cell_type":"code","source":["#Evaluating the default model of Decision tree created above\nevaluator = BinaryClassificationEvaluator(labelCol=\"default\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\nvalidation_accuracy = evaluator.evaluate(dt_model.transform(validation_df1))\nprint(\"Validation Accuracy = %g \" % (validation_accuracy))\nprint(\"Validation Error = %g \" % (1.0 - validation_accuracy))"],"metadata":{},"outputs":[],"execution_count":78},{"cell_type":"code","source":["#Extracting the tree and understanding it by visualizing\ntreeModel = dt_model.stages[-1]\nprint(treeModel)"],"metadata":{},"outputs":[],"execution_count":79},{"cell_type":"code","source":["print(treeModel.toDebugString)"],"metadata":{},"outputs":[],"execution_count":80},{"cell_type":"code","source":["display(dt_model.stages[-1])"],"metadata":{},"outputs":[],"execution_count":81},{"cell_type":"code","source":["#Understanding the prediction of the default model\ndt_prediction = dt_model.transform(testing_df1)\ndt_prediction.select(\"prediction\", \"default\", \"features\").show()"],"metadata":{},"outputs":[],"execution_count":82},{"cell_type":"code","source":["#Creating the confusion matrix of the default model for visualization \ntp = dt_prediction[(dt_prediction.default == 0) & (dt_prediction.prediction == 0)].count()\ntn = dt_prediction[(dt_prediction.default == 1) & (dt_prediction.prediction == 1)].count()\nfp = dt_prediction[(dt_prediction.default == 1) & (dt_prediction.prediction == 0)].count()\nfn = dt_prediction[(dt_prediction.default == 0) & (dt_prediction.prediction == 1)].count()\nprint(\"True Positives:\", tp)\nprint(\"True Negatives:\", tn)\nprint(\"False Positives:\", fp)\nprint(\"False Negatives:\", fn)"],"metadata":{},"outputs":[],"execution_count":83},{"cell_type":"code","source":["#Creating the visualization graph of the confusion matrix\narray = [[tp,fn],\n     [fp,tn]]        \ndf_cm = pd.DataFrame(array, range(2), range(2))\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.2)#for label size\nsns.heatmap(df_cm, annot=True, annot_kws={\"size\": 10}, cmap='YlGnBu', fmt='g')\nplt.title('Confusion Matrix for Decision Tree - Default model using Under Sampling \\n ')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.gca().invert_xaxis()\nplt.gca().invert_yaxis()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":84},{"cell_type":"markdown","source":["## Hyper Parameter Tuning"],"metadata":{}},{"cell_type":"code","source":["# Create ParamGrid for Cross Validation\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nparamGrid_dt = (ParamGridBuilder()\n                .addGrid(dt.maxDepth, [20])\n                .addGrid(dt.maxBins, [50, 60, 70])\n             .build())"],"metadata":{},"outputs":[],"execution_count":86},{"cell_type":"code","source":["from time import *\nstart_time = time()\n\nevaluatorPR = BinaryClassificationEvaluator(labelCol = \"default\", metricName = \"areaUnderROC\")\n# Create 3-fold CrossValidator\ncv_dt = CrossValidator(estimator=dt,\n                    estimatorParamMaps=paramGrid_dt,\n                    evaluator=evaluatorPR, numFolds=3)\n\n# Run cross validations\ncvModel = Pipeline(stages=[vaD, sc, cv_dt]).fit(training_df1)\n# likely take a fair amount of time\nend_time = time()\nelapsed_time = end_time - start_time\nprint(\"Time to train model: %.3f seconds\" % elapsed_time)"],"metadata":{},"outputs":[],"execution_count":87},{"cell_type":"code","source":["#extracting the best model from the grid search results\ndt_bestModel = cvModel.stages[-1].bestModel\ndt_bestModel.extractParamMap()"],"metadata":{},"outputs":[],"execution_count":88},{"cell_type":"code","source":["#Creating a pipeline with the default tasks and best model and finally fitting the model on training dataset\ntuned_dt_Model = Pipeline(stages=[vaD, sc, dt_bestModel]).fit(training_df1)\ntuned_dt_prediction = tuned_dt_Model.transform(testing_df1)\ntuned_dt_prediction.select(\"prediction\", \"default\", \"features\").show()"],"metadata":{},"outputs":[],"execution_count":89},{"cell_type":"code","source":["#Evaluating the best model with Binary Classification evaluator\nevaluator = BinaryClassificationEvaluator(labelCol=\"default\", metricName=\"areaUnderPR\")\nvalidation_accuracy = evaluator.evaluate(tuned_dt_Model.transform(validation_df1))\nprint(\"Validation Accuracy = %g \" % (validation_accuracy))\nprint(\"Validation Error = %g \" % (1.0 - validation_accuracy))"],"metadata":{},"outputs":[],"execution_count":90},{"cell_type":"code","source":["#Extracting the tree of the best model\ntreeModel = tuned_dt_Model.stages[-1]\nprint(treeModel)"],"metadata":{},"outputs":[],"execution_count":91},{"cell_type":"code","source":["print(treeModel.toDebugString)"],"metadata":{},"outputs":[],"execution_count":92},{"cell_type":"code","source":["display(dt_bestModel)"],"metadata":{},"outputs":[],"execution_count":93},{"cell_type":"code","source":["#Creating the confusion matrix of the best model\ntp = tuned_dt_prediction[(tuned_dt_prediction.default == 0) & (tuned_dt_prediction.prediction == 0)].count()\ntn = tuned_dt_prediction[(tuned_dt_prediction.default == 1) & (tuned_dt_prediction.prediction == 1)].count()\nfp = tuned_dt_prediction[(tuned_dt_prediction.default == 1) & (tuned_dt_prediction.prediction == 0)].count()\nfn = tuned_dt_prediction[(tuned_dt_prediction.default == 0) & (tuned_dt_prediction.prediction == 1)].count()\nprint(\"True Positives:\", tp)\nprint(\"True Negatives:\", tn)\nprint(\"False Positives:\", fp)\nprint(\"False Negatives:\", fn)"],"metadata":{},"outputs":[],"execution_count":94},{"cell_type":"code","source":["#Plotting the confusion matrix for visualization\narray = [[tp,fn],\n     [fp,tn]]        \ndf_cm = pd.DataFrame(array, range(2),\n                  range(2))\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.2)#for label size\nsns.heatmap(df_cm, annot=True, annot_kws={\"size\": 10}, cmap='YlGnBu', fmt='g')\nplt.title('Confusion Matrix for Decision Tree - Grid Search model using Under Sampling \\n ')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.gca().invert_xaxis()\nplt.gca().invert_yaxis()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":95},{"cell_type":"markdown","source":["##Trying Startified Sampling"],"metadata":{}},{"cell_type":"code","source":["#Implementing Stratified Sampling technique to prevent the affects of class imbalance\nstratified_data = loan_linear_reg.sampleBy('default', fractions={1: 0.9, 0: 0.40}).cache()\n\nstratified_data.groupby('default').count().show()"],"metadata":{},"outputs":[],"execution_count":97},{"cell_type":"code","source":["#Splitting the dataset \ntraining_df1, validation_df1, testing_df1 = stratified_data.randomSplit([0.6, 0.3, 0.1], seed=100)"],"metadata":{},"outputs":[],"execution_count":98},{"cell_type":"code","source":["#Creating the tasks for Decision tree: Vector Assembler,  Standard Scalar and Decision tree\nvaD = VectorAssembler(inputCols=['total_pymnt','loan_amount','installment','total_rec_prncp','interest_rate','A', 'B', 'C','D','E','F', 'MORTGAGE','NONE','OTHER','OWN','RENT','car','dti','credit_card','debt_consolidation','educational','home_improvement','house','major_purchase','medical','moving','renewable_energy','small_business','vacation','wedding','1'], outputCol='features')\nsc = StandardScaler(withMean=True, withStd=False, inputCol='features', outputCol='std_features')\ndt = DecisionTreeClassifier(featuresCol='std_features', labelCol='default')\n\n#Creating a pipeline for The tasks created above and fitting the data\ndt_model = Pipeline(stages=[vaD, sc, dt]).fit(training_df1)"],"metadata":{},"outputs":[],"execution_count":99},{"cell_type":"code","source":["#Creating an evaluator for the default model with weighted features\nevaluator = BinaryClassificationEvaluator(labelCol=\"default\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\nvalidation_accuracy = evaluator.evaluate(dt_model.transform(validation_df1))\nprint(\"Validation Accuracy = %g \" % (validation_accuracy))\nprint(\"Validation Error = %g \" % (1.0 - validation_accuracy))"],"metadata":{},"outputs":[],"execution_count":100},{"cell_type":"code","source":["#Transforming the test data by the fit model\ndt_prediction = dt_model.transform(testing_df1)\ndt_prediction.select(\"prediction\", \"default\", \"features\").show()"],"metadata":{},"outputs":[],"execution_count":101},{"cell_type":"code","source":["#Creating the confusion matrix of the defautl mdoel\ntp = dt_prediction[(dt_prediction.default == 0) & (dt_prediction.prediction == 0)].count()\ntn = dt_prediction[(dt_prediction.default == 1) & (dt_prediction.prediction == 1)].count()\nfp = dt_prediction[(dt_prediction.default == 1) & (dt_prediction.prediction == 0)].count()\nfn = dt_prediction[(dt_prediction.default == 0) & (dt_prediction.prediction == 1)].count()\nprint(\"True Positives:\", tp)\nprint(\"True Negatives:\", tn)\nprint(\"False Positives:\", fp)\nprint(\"False Negatives:\", fn)"],"metadata":{},"outputs":[],"execution_count":102},{"cell_type":"code","source":["#Visualizing the confusion matrix by graphical representation\narray = [[tp,fn],\n     [fp,tn]]        \ndf_cm = pd.DataFrame(array, range(2),\n                  range(2))\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.2)#for label size\nsns.heatmap(df_cm, annot=True, annot_kws={\"size\": 10}, cmap='YlGnBu', fmt='g')\n\nplt.title('Confusion Matrix for Decision Tree - Default model using Stratified Sampling \\n ')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.gca().invert_xaxis()\nplt.gca().invert_yaxis()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":103},{"cell_type":"markdown","source":["##Hyper Parameter Tuning"],"metadata":{}},{"cell_type":"code","source":["# Create ParamGrid for Cross Validation\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nparamGrid_dt = (ParamGridBuilder()\n                .addGrid(dt.maxDepth, [10, 20, 30])\n                .addGrid(dt.maxBins, [50, 60, 70])\n             .build())"],"metadata":{},"outputs":[],"execution_count":105},{"cell_type":"code","source":["from time import *\nstart_time = time()\n\nevaluatorPR = BinaryClassificationEvaluator(labelCol = \"default\", metricName = \"areaUnderROC\")\n# Create 3-fold CrossValidator\ncv_dt = CrossValidator(estimator=dt,\n                    estimatorParamMaps=paramGrid_dt,\n                    evaluator=evaluatorPR, numFolds=3)\n\n# Run cross validations\ncvModel = Pipeline(stages=[vaD, sc, cv_dt]).fit(training_df1)\n# likely take a fair amount of time\nend_time = time()\nelapsed_time = end_time - start_time\nprint(\"Time to train model: %.3f seconds\" % elapsed_time)"],"metadata":{},"outputs":[],"execution_count":106},{"cell_type":"code","source":["#Extracting the best model of the grid search decision tree\ndt_bestModel = cvModel.stages[-1].bestModel\ndt_bestModel.extractParamMap()"],"metadata":{},"outputs":[],"execution_count":107},{"cell_type":"code","source":["#Creating a pipeline with the best model and fitting the training data\ntuned_dt_Model = Pipeline(stages=[vaD, sc, dt_bestModel]).fit(training_df1)"],"metadata":{},"outputs":[],"execution_count":108},{"cell_type":"code","source":["#Representing the prediction of the best model\ntuned_dt_prediction = tuned_dt_Model.transform(testing_df1)\ntuned_dt_prediction.select(\"prediction\", \"default\", \"features\").show()"],"metadata":{},"outputs":[],"execution_count":109},{"cell_type":"code","source":["#Evaluating the best model's accuracy\nevaluator = BinaryClassificationEvaluator(labelCol=\"default\", metricName=\"areaUnderPR\")\nvalidation_accuracy = evaluator.evaluate(tuned_dt_Model.transform(validation_df1))\nprint(\"Validation Accuracy = %g \" % (validation_accuracy))\nprint(\"Validation Error = %g \" % (1.0 - validation_accuracy))"],"metadata":{},"outputs":[],"execution_count":110},{"cell_type":"code","source":["#Extracting the tree of the best model\ntreeModel = tuned_dt_Model.stages[-1]\nprint(treeModel)"],"metadata":{},"outputs":[],"execution_count":111},{"cell_type":"code","source":["print(treeModel.toDebugString)"],"metadata":{},"outputs":[],"execution_count":112},{"cell_type":"code","source":["display(dt_bestModel)"],"metadata":{},"outputs":[],"execution_count":113},{"cell_type":"code","source":["#Creating the confusion matrix of the best model\ntp = tuned_dt_prediction[(tuned_dt_prediction.default == 0) & (tuned_dt_prediction.prediction == 0)].count()\ntn = tuned_dt_prediction[(tuned_dt_prediction.default == 1) & (tuned_dt_prediction.prediction == 1)].count()\nfp = tuned_dt_prediction[(tuned_dt_prediction.default == 1) & (tuned_dt_prediction.prediction == 0)].count()\nfn = tuned_dt_prediction[(tuned_dt_prediction.default == 0) & (tuned_dt_prediction.prediction == 1)].count()\nprint(\"True Positives:\", tp)\nprint(\"True Negatives:\", tn)\nprint(\"False Positives:\", fp)\nprint(\"False Negatives:\", fn)"],"metadata":{},"outputs":[],"execution_count":114},{"cell_type":"code","source":["#Visualizing the confusion matrix\narray = [[tp,fn],\n     [fp,tn]]        \ndf_cm = pd.DataFrame(array, range(2),\n                  range(2))\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.2)#for label size\nsns.heatmap(df_cm, annot=True, annot_kws={\"size\": 10}, cmap='YlGnBu', fmt='g')\nplt.title('Confusion Matrix for Decision Tree - Grid Search model using Stratified Sampling \\n ')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.gca().invert_xaxis()\nplt.gca().invert_yaxis()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":115},{"cell_type":"code","source":["%sh\npip install FeatureImportanceSelector"],"metadata":{},"outputs":[],"execution_count":116},{"cell_type":"code","source":["#Feature Importance of Decision Tree\ndt_features = pd.DataFrame(list(zip(tuned_dt_prediction.toPandas()[cols], dt_model.stages[-1].featureImportances.toArray())),\n            columns = ['feature', 'importance']).sort_values('importance', ascending = False)"],"metadata":{},"outputs":[],"execution_count":117},{"cell_type":"markdown","source":["##Building a classification model using Random Forest"],"metadata":{}},{"cell_type":"code","source":["#Creating tasks for random forest \nrf_assembler = VectorAssembler(inputCols=['loan_amount','dti','total_pymnt','total_rec_prncp','recoveries','installment','interest_rate','A','B','C','D','E','F','MORTGAGE','NONE','OTHER','OWN','RENT','High','Medium','car','credit_card','debt_consolidation','educational','home_improvement','house','major_purchase','medical','moving','renewable_energy','small_business','vacation','wedding','1'], outputCol=\"features\")\nrf = classification.RandomForestClassifier(featuresCol = \"features\", labelCol = \"default\")"],"metadata":{},"outputs":[],"execution_count":119},{"cell_type":"code","source":["#Random Forest Pipeline and fitting training data\npipe_rf = Pipeline(stages = [rf_assembler,rf]).fit(training_df1)"],"metadata":{},"outputs":[],"execution_count":120},{"cell_type":"code","source":["#Creating an evaluator for the random forest model\nevaluator = evaluation.BinaryClassificationEvaluator(labelCol='default', metricName='areaUnderROC')"],"metadata":{},"outputs":[],"execution_count":121},{"cell_type":"code","source":["#Evaluating the random forest model\nAUC = evaluator.evaluate(pipe_rf.transform(validation_df1))\nprint(AUC)"],"metadata":{},"outputs":[],"execution_count":122},{"cell_type":"code","source":["#Transforming test data on the model\nrf_prediction = pipe_rf.transform(testing_df1)\nrf_prediction.select(\"prediction\", \"default\", \"features\").show()"],"metadata":{},"outputs":[],"execution_count":123},{"cell_type":"code","source":["#Creating the confusion matrix for the default model of random forest\ntp = rf_prediction[(rf_prediction.default == 0) & (rf_prediction.prediction == 0)].count()\ntn = rf_prediction[(rf_prediction.default == 1) & (rf_prediction.prediction == 1)].count()\nfp = rf_prediction[(rf_prediction.default == 1) & (rf_prediction.prediction == 0)].count()\nfn = rf_prediction[(rf_prediction.default == 0) & (rf_prediction.prediction == 1)].count()\nprint(\"True Positives:\", tp)\nprint(\"True Negatives:\", tn)\nprint(\"False Positives:\", fp)\nprint(\"False Negatives:\", fn)"],"metadata":{},"outputs":[],"execution_count":124},{"cell_type":"code","source":["#Visualizing the confusion matrix by graphical representation\narray = [[tp,fn],\n     [fp,tn]]        \ndf_cm = pd.DataFrame(array, range(2),\n                  range(2))\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.2)#for label size\nsns.heatmap(df_cm, annot=True, annot_kws={\"size\": 10}, cmap='YlGnBu', fmt='g')\nplt.title('Confusion Matrix for Random Forest - Default model using Stratified Sampling \\n ')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.gca().invert_xaxis()\nplt.gca().invert_yaxis()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":125},{"cell_type":"markdown","source":["##Hyper Parameter Tuning"],"metadata":{}},{"cell_type":"code","source":["#Creating a paramGrid for grid search\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nparamGrid = (ParamGridBuilder()\n             .addGrid(rf.numTrees, [25,30,35])\n             .addGrid(rf.maxDepth, [6,10,12])\n             .build())"],"metadata":{},"outputs":[],"execution_count":127},{"cell_type":"code","source":["#Creating evalutor for Random forest model\nrf_evaluator = BinaryClassificationEvaluator(labelCol='default', metricName = 'areaUnderROC')"],"metadata":{},"outputs":[],"execution_count":128},{"cell_type":"code","source":["from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\ncv_rf= CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=rf_evaluator, numFolds=3)\n    \n# Run cross validations\ncv_rf_Model = Pipeline(stages = [rf_assembler, cv_rf]).fit(training_df1)"],"metadata":{},"outputs":[],"execution_count":129},{"cell_type":"code","source":["#Printing the AUC for the grid search model\nprint(\"The area under ROC for validation set after CV  is {}\".format(rf_evaluator.evaluate(cv_rf_Model.transform(validation_df1))))"],"metadata":{},"outputs":[],"execution_count":130},{"cell_type":"code","source":["#Extracting the best model of Random Forest\nbest_model = cv_rf_Model.stages[-1].bestModel\nbest_model.extractParamMap()"],"metadata":{},"outputs":[],"execution_count":131},{"cell_type":"code","source":["print(\"The area under ROC for testing set after CV  is {}\".format(rf_evaluator.evaluate(cv_rf_Model.transform(testing_df1))))"],"metadata":{},"outputs":[],"execution_count":132},{"cell_type":"code","source":["#Creating a Random Forest Pipeline with the best mdoel\nrf_model = Pipeline(stages = [rf_assembler, best_model]).fit(training_df1)"],"metadata":{},"outputs":[],"execution_count":133},{"cell_type":"code","source":["#Transforming the test data on the fit model\nrf_prediction = rf_model.transform(testing_df1)\nrf_prediction.select(\"prediction\", \"default\", \"features\").show()"],"metadata":{},"outputs":[],"execution_count":134},{"cell_type":"code","source":["#Creating the confusion matrix of the best model\ntp = rf_prediction[(rf_prediction.default == 0) & (rf_prediction.prediction == 0)].count()\ntn = rf_prediction[(rf_prediction.default == 1) & (rf_prediction.prediction == 1)].count()\nfp = rf_prediction[(rf_prediction.default == 1) & (rf_prediction.prediction == 0)].count()\nfn = rf_prediction[(rf_prediction.default == 0) & (rf_prediction.prediction == 1)].count()\nprint(\"True Positives:\", tp)\nprint(\"True Negatives:\", tn)\nprint(\"False Positives:\", fp)\nprint(\"False Negatives:\", fn)"],"metadata":{},"outputs":[],"execution_count":135},{"cell_type":"code","source":["#Visualizing the confusion matrix\narray = [[tp,fn],\n     [fp,tn]]        \ndf_cm = pd.DataFrame(array, range(2),\n                  range(2))\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.2)#for label size\nsns.heatmap(df_cm, annot=True, annot_kws={\"size\": 10}, cmap='YlGnBu', fmt='g')\nplt.title('Confusion Matrix for Random Forest - Grid Search model using Stratified Sampling \\n ')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.gca().invert_xaxis()\nplt.gca().invert_yaxis()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":136},{"cell_type":"code","source":["#Extracting the feature importances and sorting them according to their importance from higher order to lower\nrf_features = pd.DataFrame(list(zip(rf_prediction.toPandas()[cols], rf_model.stages[-1].featureImportances.toArray())),\n            columns = ['feature', 'importance']).sort_values('importance', ascending = False)"],"metadata":{},"outputs":[],"execution_count":137},{"cell_type":"code","source":["rf_features"],"metadata":{},"outputs":[],"execution_count":138},{"cell_type":"markdown","source":["#Inference"],"metadata":{}},{"cell_type":"code","source":["#Visualizing feature importance of the Random Forest (barplot)\nplt.figure(figsize=(18,7))\nax = sns.barplot(x=\"feature\", y=\"importance\", data=rf_features.head(10), saturation=.5)\nax.set_title('Feature Importance by Random Forest')\nax.set_ylabel('Feature Importance')\nax.set_xlabel('Features')\ndisplay(ax.figure)"],"metadata":{},"outputs":[],"execution_count":140},{"cell_type":"code","source":["#Visualizing feature importance by Decision Tree (Bar Plot)\nplt.figure(figsize=(18,7))\nax = sns.barplot(x=\"feature\", y=\"importance\", data=dt_features.head(6), saturation=.5)\nax.set_title('Feature Importance by Decision Tree')\nax.set_ylabel('Feature Importance')\nax.set_xlabel('Features')\ndisplay(ax.figure)"],"metadata":{},"outputs":[],"execution_count":141},{"cell_type":"code","source":["#Visualizign feature importance by logistic Regression\nplt.figure(figsize=(18,7))\nax = sns.barplot(x=\"column\", y=\"weight\", data=lr_best_feature.head(10), saturation=.5)\n#ax.set_xticklabels(ax.get_xticklabels(), rotation=20)\nax.set_title('Feature Importance by Logistic Regression')\nax.set_ylabel('Feature Weights')\nax.set_xlabel('Features')\ndisplay(ax.figure)"],"metadata":{},"outputs":[],"execution_count":142},{"cell_type":"code","source":["#Creating model comparison dataframe\nname = ['Logistic Regression', 'Decision Tree', 'Random Forest']\nAccuracy = [0.79, 0.727, 0.855]\nresult_df = pd.DataFrame(list(zip(name, Accuracy)), columns =['Model', 'Accuracy'])\nresult_df.head()"],"metadata":{},"outputs":[],"execution_count":143},{"cell_type":"markdown","source":["#Model Comparison"],"metadata":{}},{"cell_type":"code","source":["#Visualizing the model comparison\nplt.figure(figsize=(7,5))\nax = sns.barplot(x=\"Model\", y=\"Accuracy\", data=result_df, saturation=.5)\n#ax.set_xticklabels(ax.get_xticklabels(), rotation=20)\nax.set_title('Model Comparison')\nax.set_ylabel('Model Accuracy')\nax.set_xlabel('Models Implemented')\ndisplay(ax.figure)"],"metadata":{},"outputs":[],"execution_count":145},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":146}],"metadata":{"name":"Default_Loan_Predicition","notebookId":2593308028211371},"nbformat":4,"nbformat_minor":0}
